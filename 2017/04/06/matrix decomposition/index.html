<!doctype html>




<html class="theme-next muse" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="预备   定义1，给定一个由\(n\)维向量集合组成的集合\(V\)，如果集合\(V\)非空并且对于任意集合\(V\)中的向量，满足如下两个条件    若\(a\in V,b\in V\) ,则\(a+b\in V\)；  若\(a\in V,\lambda \in R\)，则\(\lambda a \in V\)； 则称集合\(V\)为向量空间   定义1说明在向量空间">
<meta name="keywords">
<meta property="og:type" content="article">
<meta property="og:title" content="矩阵分解及其应用">
<meta property="og:url" content="http://yoursite.com/2017/04/06/matrix decomposition/index.html">
<meta property="og:site_name" content="欢迎光临我的技术博客">
<meta property="og:description" content="预备   定义1，给定一个由\(n\)维向量集合组成的集合\(V\)，如果集合\(V\)非空并且对于任意集合\(V\)中的向量，满足如下两个条件    若\(a\in V,b\in V\) ,则\(a+b\in V\)；  若\(a\in V,\lambda \in R\)，则\(\lambda a \in V\)； 则称集合\(V\)为向量空间   定义1说明在向量空间">
<meta property="og:image" content="http://yoursite.com/img/1.jpg">
<meta property="og:image" content="http://yoursite.com/img/2.jpg">
<meta property="og:image" content="http://yoursite.com/img/3.jpg">
<meta property="og:image" content="http://yoursite.com/img/4.jpg">
<meta property="og:image" content="http://yoursite.com/img/5.jpg">
<meta property="og:image" content="http://yoursite.com/img/lena.jpg">
<meta property="og:image" content="http://yoursite.com/img/6.jpg">
<meta property="og:image" content="http://yoursite.com/img/pic.jpg">
<meta property="og:image" content="http://yoursite.com/img/7.jpg">
<meta property="og:image" content="http://yoursite.com/img/8.jpg">
<meta property="og:image" content="http://yoursite.com/img/9.jpg">
<meta property="og:image" content="http://yoursite.com/img/10.jpg">
<meta property="og:image" content="http://yoursite.com/img/11.jpg">
<meta property="og:image" content="http://yoursite.com/img/12.jpg">
<meta property="og:image" content="http://yoursite.com/img/13.jpg">
<meta property="og:updated_time" content="2017-04-23T07:01:19.358Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="矩阵分解及其应用">
<meta name="twitter:description" content="预备   定义1，给定一个由\(n\)维向量集合组成的集合\(V\)，如果集合\(V\)非空并且对于任意集合\(V\)中的向量，满足如下两个条件    若\(a\in V,b\in V\) ,则\(a+b\in V\)；  若\(a\in V,\lambda \in R\)，则\(\lambda a \in V\)； 则称集合\(V\)为向量空间   定义1说明在向量空间">
<meta name="twitter:image" content="http://yoursite.com/img/1.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: false,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/04/06/matrix decomposition/"/>





  <title> 矩阵分解及其应用 | 欢迎光临我的技术博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">欢迎光临我的技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">吹一吹</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/06/matrix decomposition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jingchen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="欢迎光临我的技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                矩阵分解及其应用
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-06T22:23:00+08:00">
                2017-04-06
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/04/06/matrix decomposition/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/06/matrix decomposition/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="预备">预备</h2>
<blockquote>
<ul>
<li>定义1，给定一个由<span class="math inline">\(n\)</span>维向量集合组成的集合<span class="math inline">\(V\)</span>，如果集合<span class="math inline">\(V\)</span>非空并且对于任意集合<span class="math inline">\(V\)</span>中的向量，满足如下两个条件<br>
</li>
</ul>
<ol style="list-style-type: decimal">
<li>若<span class="math inline">\(a\in V,b\in V\)</span> ,则<span class="math inline">\(a+b\in V\)</span>；<br>
</li>
<li>若<span class="math inline">\(a\in V,\lambda \in R\)</span>，则<span class="math inline">\(\lambda a \in V\)</span>；<br>
则称集合<span class="math inline">\(V\)</span>为向量空间</li>
</ol>
</blockquote>
<p>定义1说明在向量空间中，对向量加和运算和向量数乘运算封闭</p>
<blockquote>
<ul>
<li>定义2，设<span class="math inline">\(V\)</span>为向量空间，如果<span class="math inline">\(r\)</span>个向量<span class="math inline">\(a_{1},a_{2}，\cdots，a_{n} \in V\)</span>，并且满足<br>
1)<span class="math inline">\(a_{1},a_{2}，\cdots，a_{n}\)</span>线性无关；<br>
2)<span class="math inline">\(V\)</span>中任一向量都可由<span class="math inline">\(a_{1},a_{2}，\cdots，a_{n}\)</span>线性标示；<br>
则称向量组<span class="math inline">\(a_{1},a_{2}，\cdots，a_{n}\)</span>为向量空间<span class="math inline">\(V\)</span>的一个基，<span class="math inline">\(n\)</span>称为向量空间<span class="math inline">\(V\)</span>的维数</li>
</ul>
</blockquote>
给定向量空间<span class="math inline">\(V\)</span>下的一个向量<span class="math inline">\(x\)</span>，如果存在<br>

<center>
<span class="math inline">\(x=\lambda_{1}a_{1}+\lambda_{2}a_{2}+\cdots+\lambda_{n}a_{n}\)</span>
</center>
则称数组<span class="math inline">\(\lambda_{1},\lambda_{2},\cdots,\lambda_{n}\)</span>为向量<span class="math inline">\(x\)</span>在基<span class="math inline">\(a_{1},a_{2}，\cdots，a_{n}\)</span>下的坐标，向量<span class="math inline">\(x\)</span>在基<span class="math inline">\(a_{1},a_{2}，\cdots，a_{n}\)</span>下可以表示为<br>

<center>
<span class="math inline">\(x=[\lambda_{1}, \lambda_{2},\cdots,\lambda_{n}]\)</span>
</center>
<blockquote>
<ul>
<li>定义3，自然基，在<span class="math inline">\(n\)</span>维向量空间中取单位坐标向量组<span class="math inline">\(e_{1},e_{2},\cdots e_{n}\)</span>作为基，向量空间中的任一向量可以表示为<span class="math inline">\(x=x_{1}e_{1} + x_{2}e_{2}+ \cdots + x_{n}e_{n}\)</span>,称<span class="math inline">\(e_{1},e_{2},\cdots e_{n}\)</span>为自然基，向量<span class="math inline">\(x=[x_{1},x_{2},\cdots,x_{n}]\)</span></li>
</ul>
</blockquote>
<p>在定义3中的自然基，任何两个基向量的内积为0，称基向量之间正交，每个基的模为1，称为单位向量。对一个基，如果任意一个向量为单位向量且任意两个向量正交，则称为规范正交基。</p>
<blockquote>
<ul>
<li>定义4，正交矩阵，如果一个<span class="math inline">\(n\)</span>阶方阵满足<span class="math inline">\(A^TA=E(即A^{-1}=A^T)\)</span>，则称方阵<span class="math inline">\(A\)</span>为正交矩阵</li>
</ul>
</blockquote>
从正交矩阵的定义，可以导出正交矩阵行矩阵或列矩阵两两正交且模为1，假设<span class="math inline">\(A\)</span>列矩阵为<br>

<center>
$A^{T}A=
<span class="math display">\[\begin{bmatrix}
x_{1}^{T}\\ 
x_{2}^{T}\\ 
\vdots\\ 
x_{n}^{T}
\end{bmatrix}\begin{bmatrix}
x_{1} &amp;x_{2}  &amp; \cdots  &amp; x_{n} 
\end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix}
1 &amp; 0 &amp;  0&amp; 0\\ 
0 &amp; 1 &amp;  0&amp; 0\\ 
\vdots &amp;  \vdots&amp; \vdots &amp; \vdots\\ 
 0&amp; 0 &amp; 0 &amp; 1
\end{bmatrix}\]</span>
a_{i}^{T}a_{j}=_{ij} = {
<span class="math display">\[\begin{matrix}
1,如果i=j\\ 
0,否则i\ne j
\end{matrix}\]</span>
. $
</center>
<blockquote>
<ul>
<li>定义5，称变换<span class="math inline">\(T\)</span>是线性的，如果<br>
1）对于<span class="math inline">\(T\)</span>定义域内的一切<span class="math inline">\(u,v\)</span>，<span class="math inline">\(T(u+v)=T(u)+T(v)\)</span><br>
</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>对一切<span class="math inline">\(u\)</span>和标量c，<span class="math inline">\(T(cu)=cT(u)\)</span><br>
</li>
</ol>
<ul>
<li>定义6，矩阵变换，称一个矩阵乘以一个向量为一个矩阵变换，记作<span class="math inline">\(x\to Ax\)</span></li>
</ul>
</blockquote>
<p>一个变换就是一个映射，由定义可以看出，矩阵变换<span class="math inline">\(x\to Ax\)</span>是一个线性变换</p>
<h2 id="矩阵的几何意义">矩阵的几何意义</h2>
我们知道对于一个向量，给定一组基下就会有一个坐标唯一描述这个向量，假如有两个基描述这个向量，这两个基有什么关系呢？假设向量空间<span class="math inline">\(V\)</span>有两组基<span class="math inline">\(a_{1},a_{2},\cdots,a_{n}和b_{1},b_{2},\cdots,b_{n}\)</span>，则基<span class="math inline">\(b\)</span>可以由<span class="math inline">\(a\)</span>来表示，即有
<center>
<span class="math inline">\(\left\{\begin{matrix} b_{1}=p_{11}a_{1}+p_{21}a_{2}+\cdots +p_{n1}a_{n}\\ b_{2}=p_{12}a_{1}+p_{22}a_{2}+\cdots +p_{n2}a_{n}\\ \cdots \\ b_{n}=p_{1n}a_{1}+p_{2n}a_{2}+\cdots +p_{nn}a_{n} \end{matrix}\right.\)</span>
</center>
写成矩阵形式，则有
<center>
$
<span class="math display">\[\begin{bmatrix}
b_{1}\\ 
b_{2}\\ 
\vdots\\ 
b_{n}
\end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix}
p_{11} &amp; p_{21} &amp; \cdots &amp; p_{n1}\\ 
p_{12} &amp; p_{22} &amp; \cdots &amp; p_{n2}\\ 
\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\ 
p_{1n} &amp; p_{n2} &amp; \cdots &amp; p_{nn}
\end{bmatrix}\begin{bmatrix}
a_{1}\\ 
a_{2}\\ 
\vdots\\ 
a_{n}
\end{bmatrix}\]</span>
=P^{T}
<span class="math display">\[\begin{bmatrix}
a_{1}\\ 
a_{2}\\ 
\vdots\\ 
a_{n}
\end{bmatrix}\]</span>
$
</center>
<p>称矩阵<span class="math inline">\(P\)</span>为从基<span class="math inline">\(a\)</span>到基<span class="math inline">\(b\)</span>的过渡矩阵,因为基是线性无关的，因此矩阵<span class="math inline">\(P\)</span>是可逆的，也就是说，两个基之间可以通过一个矩阵来转换。</p>
<blockquote>
<ul>
<li>定理1，设<span class="math inline">\(V_{n}\)</span>中的一个向量<span class="math inline">\(r\)</span>,在基<span class="math inline">\(a_{1},a_{2},\cdots,a_{n}\)</span>下的坐标为<span class="math inline">\([ x_{1},x_{2},\cdots,x_{n}]\)</span>，在基<span class="math inline">\(b_{1},b_{2},\cdots,b_{n}\)</span>下的坐标为<span class="math inline">\([x_{1}&#39;,x_{2}&#39;,\cdots,x_{n}&#39;]\)</span>，矩阵<span class="math inline">\(P\)</span>为从基<span class="math inline">\(a\)</span>到基<span class="math inline">\(b\)</span>的过渡矩阵，则有坐标变换公式
<center>
<span class="math inline">\(\begin{bmatrix} x_{1}\\ x_{2}\\ \vdots\\ x_{n} \end{bmatrix} = P \begin{bmatrix} x_{1}&#39;\\ x_{2}&#39;\\ \vdots\\ x_{n}&#39; \end{bmatrix}\)</span>
</center></li>
</ul>
</blockquote>
来看一个特殊的情况，假设基向量<span class="math inline">\(a\)</span>为自然基，则有
<center>
$
<span class="math display">\[\begin{bmatrix}
b_{1}\\ 
b_{2}\\ 
\vdots\\ 
b_{n}
\end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix}
p_{11} &amp; p_{21} &amp; \cdots &amp; p_{n1}\\ 
p_{12} &amp; p_{22} &amp; \cdots &amp; p_{n2}\\ 
\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\ 
p_{1n} &amp; p_{n2} &amp; \cdots &amp; p_{nn}
\end{bmatrix}\begin{bmatrix}
a_{1}\\ 
a_{2}\\ 
\vdots\\ 
a_{n}
\end{bmatrix}\]</span>
=P^{T} $
</center>
因此，一个向量在标准坐标系下坐标为<span class="math inline">\(x=[x_{1},x_{2},\cdots,x_{n}]\)</span>,在基<span class="math inline">\(b\)</span>下的坐标为<span class="math inline">\(x&#39;=x^{T}[b_{1}^{T},b_{2}^{T},\cdots,b_{n}^{T}]\)</span>,公式也可以写作
<center>
<span class="math inline">\(EX^{T}=BX&#39;^{T}\)</span>
</center>
<p>也就是矩阵乘法<span class="math inline">\(AX=b\)</span>可以认为是在标准坐标系下坐标是<span class="math inline">\(b\)</span>，在<span class="math inline">\(A\)</span>组成的基下的坐标是<span class="math inline">\(x\)</span></p>
<p>给定一个矩阵<span class="math inline">\(A\)</span>,矩阵<span class="math inline">\(Ax\)</span>可以看成一个基变换，如果认为基变换前后是同一个基，则可以认为<span class="math inline">\(Ax\)</span>是对向量进行角度及长度的变换，矩阵可以认为是一个线性变换，也就是变换基坐标和变换向量是相对的</p>
下面用二维图示进行说明，给定一个二维对角矩阵
<center>
<span class="math inline">\(M=\begin{bmatrix} 3 &amp; 0\\ 0 &amp; 1 \end{bmatrix}\)</span>
</center>
从几何上讲，<span class="math inline">\(M\)</span>是将二维平面上的点<span class="math inline">\((x,y)\)</span>经过线性变换到另外一个点的变换矩阵
<center>
$M=
<span class="math display">\[\begin{bmatrix}
3 &amp; 0\\ 
0 &amp; 1
\end{bmatrix}\begin{bmatrix}
x\\ 
y
\end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix}
3x\\ 
y
\end{bmatrix}\]</span>
$
</center>
变换的效果如下图所示，变换后的平面仅仅是沿 X 水平方面进行了拉伸3倍，垂直方向是并没有发生变化。
<center>
<img src="/img/1.jpg">
</center>
现在看下矩阵
<center>
$M=
<span class="math display">\[\begin{bmatrix}
2 &amp; 1\\ 
1 &amp; 2
\end{bmatrix}\begin{bmatrix}
x\\ 
y
\end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix}
2x+y\\ 
x+2y
\end{bmatrix}\]</span>
$
</center>
这个矩阵产生的变换效果如下图所示
<center>
<img src="/img/2.jpg">
</center>
这种变换效果看起来非常的奇怪，在实际环境下很难描述出来变换的规律 ( 这里应该是指无法清晰辨识出旋转的角度，拉伸的倍数之类的信息)。还是基于上面的对称矩阵，假设我们把左边的平面旋转45度角，然后再进行矩阵<span class="math inline">\(M\)</span>的线性变换，效果如下图所示：
<center>
<img src="/img/3.jpg">
</center>
<p>看起来是不是有点熟悉？ 对的，经过 M 线性变换后，跟前面的对角矩阵的功能是相同的，都是将网格沿着一个方向拉伸了3倍。</p>
<p>从上边看出，一个矩阵可以对向量进行旋转和拉伸作用，有没有矩阵对向量仅仅进行旋转变化，不进行拉伸呢？正交变换就仅仅对向量进行旋转，不进行拉伸</p>
<blockquote>
<ul>
<li>定理二，若<span class="math inline">\(P\)</span>为正交矩阵，则线性变换<span class="math inline">\(y=Px\)</span>称为正交变换，并且变换后向量大小不变</li>
</ul>
</blockquote>
向量是否拉伸可以通过向量的2阶范数来反映，即
<center>
<span class="math inline">\(\parallel y \parallel =\sqrt{y^{T}y}=\sqrt{x^{T}P^{T}Px}=\sqrt{x^{T}x}=\parallel x \parallel\)</span>
</center>
<p>下面以一个图示来演示正交变换,假设二维空间中的一个向量<span class="math inline">\(OA\)</span>，它在标准坐标系也即<span class="math inline">\(e1、e2\)</span>表示的坐标是中表示为<span class="math inline">\((a,b)^{T}\)</span>，现在把它用另一组坐标<span class="math inline">\(e1&#39;、e2&#39;\)</span>表示为<span class="math inline">\((a&#39;,b&#39;)^{T}\)</span>，存在矩阵<span class="math inline">\(U\)</span>使得<span class="math inline">\(U(a&#39;,b&#39;)^{T}=(a,b)^{T}\)</span></p>
<center>
<img src="/img/4.jpg">
</center>
容易求出<span class="math inline">\(U\)</span>，其中<span class="math inline">\(e_{1}&#39;=[\cos\theta,\sin\theta]^{T}，e_{2}&#39;=[-\sin\theta,\cos\theta]\)</span>，因此
<center>
<span class="math inline">\(U=\begin{bmatrix} \cos\theta &amp; -\sin\theta\\ \sin\theta &amp; \cos\theta \end{bmatrix}\)</span>
</center>
下图展示了基变换和向量方向变换的等价
<center>
<img src="/img/5.jpg">
</center>
<p>有没有矩阵变换，仅仅对向量进行拉伸，不改变方向呢，这就是方阵的特征值和特征向量</p>
<h2 id="方阵的特征值及特征向量">方阵的特征值及特征向量</h2>
<blockquote>
<ul>
<li>定义7，设<span class="math inline">\(A\)</span>是<span class="math inline">\(n\)</span>阶矩阵，如果<span class="math inline">\(\lambda\)</span>和<span class="math inline">\(n\)</span>维非零列向量<span class="math inline">\(x\)</span>满足如下关系
<center>
<span class="math inline">\(Ax=\lambda x\)</span>
</center>
则称<span class="math inline">\(\lambda\)</span>为矩阵<span class="math inline">\(A\)</span>的特征值，向量<span class="math inline">\(x\)</span>为矩阵<span class="math inline">\(A\)</span>的特征向量</li>
</ul>
</blockquote>
从定义看出，矩阵<span class="math inline">\(A\)</span>仅仅对特征向量进行了<span class="math inline">\(\lambda\)</span>的拉伸，假设所有的特征值组成可逆矩阵<span class="math inline">\(Q\)</span>，特征值组成对角矩阵<span class="math inline">\(\Sigma\)</span>，则矩阵<span class="math inline">\(A\)</span>可以分解为
<center>
<span class="math inline">\(A=Q\Sigma Q^{-1}\)</span>
</center>
<p>以上称为矩阵的特征值分解</p>
<blockquote>
<ul>
<li>定义8，矩阵的相似性，设<span class="math inline">\(A,B\)</span>都是<span class="math inline">\(n\)</span>阶矩阵，如果存在可逆矩阵<span class="math inline">\(P\)</span>,使得，
<center>
<span class="math inline">\(P^{-1}AP=B\)</span>
</center>
则称<span class="math inline">\(A,B\)</span>相似</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>定理三，如果<span class="math inline">\(n\)</span>阶矩阵<span class="math inline">\(A,B\)</span>相似，则他们有相同的特征多项式，从而有相同的特征值</li>
</ul>
</blockquote>
<p>容易证明</p>
<center>
$| B-E | = | P<sup>{-1}AP-P</sup>{-1}(E)P | = | P^{-1}(A- E)P | = | P^{-1} | | A- E | | P | = | A-E | $
</center>
<p>因此，如果一个矩阵<span class="math inline">\(A\)</span>跟一个上(下)三角矩阵或者对角阵相似，则对角线的<span class="math inline">\(n\)</span>个值就是<span class="math inline">\(A\)</span>的特征值。同理，对于<span class="math inline">\(n\)</span>阶矩阵<span class="math inline">\(A\)</span>，能否找到一个可逆矩阵<span class="math inline">\(P\)</span>使得<span class="math inline">\(P^{-1}AP=\Lambda\)</span>，其中<span class="math inline">\(\Lambda\)</span>为对角矩阵，如果存在，则称方阵<span class="math inline">\(A\)</span>的对角化分解。</p>
<p>首先来看如果存在可逆矩阵<span class="math inline">\(P\)</span>，它会满足什么条件，根据定义，把可逆矩阵写成列向量，即<span class="math inline">\(P=(p_{1},p_{2},\cdots,p_{n})\)</span> ，根据<span class="math inline">\(P^{-1}AP=\Lambda\)</span> ,有<span class="math inline">\(AP=\Lambda P\)</span>,既有</p>
<center>
<span class="math inline">\(A(p_{1},p_{2},\cdots,p_{n})=(p_{1},p_{2},\cdots,p_{n})\begin{bmatrix} \lambda_{1} &amp; &amp; &amp; \\  &amp; \lambda_{2} &amp; &amp; \\  &amp; &amp; \ddots &amp; \\  &amp; &amp; &amp; \lambda_{n} \end{bmatrix} =(\lambda_{1}p_{1},\lambda_{2}p_{2},\cdots,\lambda_{n}p_{n})\)</span>
</center>
<p>即，如果矩阵<span class="math inline">\(A\)</span>能对角化，则对角化<span class="math inline">\(\Lambda\)</span>为特征值组成的对角矩阵，可逆矩阵为特征向量组成的矩阵，因此特征值分解可以实现矩阵的对角化分解。</p>
<blockquote>
<ul>
<li>定理四，一个<span class="math inline">\(n\)</span>矩阵能够对角化的充分必要条件是它有<span class="math inline">\(n\)</span>个线性无关的特征向量。特别的，对于对称矩阵<span class="math inline">\(A(即A^{T}=A)\)</span>，它的任意两个不同特征值对应的特征向量正交；并且必有正交阵<span class="math inline">\(P\)</span>，使
<center>
<span class="math inline">\(P^{-1}AP=P^{T}AP=\Lambda\)</span>
</center>
<span class="math inline">\(\Lambda\)</span>为特征值组成的对角化矩阵</li>
</ul>
</blockquote>
<h4 id="矩阵相似的意义">矩阵相似的意义</h4>
我们知道矩阵对应一个在给定基下的线性变换，如果同一个线性变换，在基<span class="math inline">\(a\)</span>下的变换矩阵为<span class="math inline">\(A\)</span>，在<span class="math inline">\(b\)</span>下的变换矩阵为B，则<span class="math inline">\(A,B\)</span>有什么关系呢? 根据基变换的性质，基<span class="math inline">\(b\)</span>可以由基<span class="math inline">\(a\)</span>和一个矩阵乘积来表示，即<span class="math inline">\(b=aP\)</span>，则对于线性变换<span class="math inline">\(L\)</span>有
<center>
<span class="math inline">\(\begin{array}{l} L(b)=L(a)P \\ \Rightarrow {[ L(b_1) \cdots L(b_n) ] = [ L(a_1) \cdots L(a_n) ]\; P }\\ \Rightarrow {(b_1\cdots b_n)B=(a_1\cdots a_n)AP}\\ \Rightarrow {(a_1\cdots a_n)PB=(a_1\cdots a_n)AP}\\ \Rightarrow {PB=AP} \\ \Rightarrow {B=P^{-1}AP} \end{array}\)</span>
</center>
<p>也就是说，两个矩阵相似，表示这两个矩阵是在不同的基表示下的同一个线性变换，特别，可逆矩阵<span class="math inline">\(P\)</span>为两个基的过渡矩阵</p>
<h4 id="特征值及特征向量的意义">特征值及特征向量的意义</h4>
<p>根据矩阵相似的意义，方阵<span class="math inline">\(A\)</span>的特征值分解可以理解两个不同基下的同一个变换，其中特征向量组成的矩阵是两个变换的过渡矩阵，特别的，假设其中一个基是自然基，则另一个基为<span class="math inline">\(P\)</span>或者<span class="math inline">\(P^{-1}\)</span>，假设对角阵对应的基为自然基，则方阵<span class="math inline">\(A\)</span>对应的基为<span class="math inline">\(P\)</span>，也就是向量<span class="math inline">\(A\)</span>的变换是对自然基组成的向量做特征值大小的缩放。</p>
<p>从线性空间的角度看，在一个定义了内积的线性空间里，对一个<span class="math inline">\(n\)</span>阶对称方阵进行特征分解，就是产生了该空间的<span class="math inline">\(n\)</span>个标准正交基，然后把矩阵投影到这<span class="math inline">\(n\)</span>个基上。<span class="math inline">\(n\)</span>个特征向量就是<span class="math inline">\(n\)</span>个标准正交基，因为对称方阵的特征向量是一个正交矩阵，所以，而特征值的模则代表矩阵在每个基上的投影长度。特征值越大，说明矩阵在对应的特征向量上的方差越大，功率越大，信息量越多。</p>
对于小方阵，特征值及特征向量可以通过定义来求得。下面来看怎么求特征值及特征向量，由定义式可有
<center>
<span class="math inline">\((A-\lambda E)x=0\)</span>
</center>
这是一个<span class="math inline">\(n\)</span>个未知数<span class="math inline">\(n\)</span>个方程的齐次线性方程组，因它有非零解的条件是特征多项式为<span class="math inline">\(0\)</span>，即
<center>
<span class="math inline">\(\left |A-\lambda E \right |=0\)</span>
</center>
<p>假设<span class="math inline">\(n\)</span>阶方阵<span class="math inline">\(A\)</span>的特征值分别为<span class="math inline">\(\lambda_{1},\lambda_{2},\cdots,\lambda_{n}\)</span>，特征值有如下性质<br>
* 1) <span class="math inline">\(\lambda_{1}+\lambda_{2}+\cdots+\lambda_{n} = a_{11}+a_{22}+\cdots+a_{nn}\)</span><br>
* 2) <span class="math inline">\(\lambda_{1}\lambda_{2}\cdots\lambda_{n}=\left |A\right|\)</span></p>
<p>但对于大型的方阵，可以通过矩阵的QR分解来求。</p>
<h2 id="矩阵的奇异值分解">矩阵的奇异值分解</h2>
<p>根据特征值分解的描述，特征值的大小可以看成矩阵在某一方向的拉伸大小，如果矩阵在某些方向上的拉伸比较小，也就是特征值比较小，如果不考虑这些特征值的影响，矩阵的变换作用影响不大，因此可以用特征值分解来降维。</p>
<p>上面讲的特征值分解是针对方阵的，那么对于普通的矩阵，会有这样的分解吗？其实，对于任何矩阵矩阵<span class="math inline">\(A_{mn}\)</span>，存在一个正交矩阵<span class="math inline">\(U_{mm}\)</span>，一个正交矩阵<span class="math inline">\(V_{nn}\)</span>，一个对角矩阵<span class="math inline">\(\Lambda_{mn}\)</span>，使得</p>
<center>
<span class="math inline">\(A_{mn}=U_{mm}\Lambda_{mn}V^{T}_{nn}\)</span>
</center>
<p>成立，这就是矩阵的奇异值分解。</p>
首先对于任何<span class="math inline">\(A_{mn}\)</span>，都有<span class="math inline">\(A^{T}A\)</span>是对称矩阵，根据对称矩阵的特征分解，有
<center>
<span class="math inline">\(A=Q\Sigma Q^{-1}\)</span>
</center>
<p>假设我们得到一组正交基<span class="math inline">\({v_1,v_2,\cdots,v_n}\)</span>，即<span class="math inline">\(A^{T}Av_i = \lambda_iv_i\)</span>，下面看对正交基进行<span class="math inline">\(A\)</span>线性变换的向量组<span class="math inline">\({Av_1,Av_2,\cdots,Av_n}\)</span></p>
<center>
$(Av_{i},Av_{j})\ =(Av_{i})<sup>{T}(Av_{j})\ =v</sup>{T}<em>{i}A<sup>{T}Av_{j}\ =v</sup>{T}</em>{i}(<em>{j}v</em>{j})\ =_{j}v^{T}<em>iv</em>{j}\ =0 $
</center>
也就是经过矩阵<span class="math inline">\(A\)</span>线性变换后的基<span class="math inline">\({Av_1,Av_2,\cdots,Av_n}\)</span>也是正交的，将其标准化，即将<span class="math inline">\(Av_{i}\)</span>变换为
<center>
<span class="math display">\[u_{i}=\frac{Av_{i}}{\left | Av_{i} \right | } = \frac{1}{\sqrt{\lambda_{i}}}Av_{i}\]</span>
</center>
<p>如果令<span class="math inline">\(\delta_{i} = \sqrt{\lambda_{i}}\)</span>，称<span class="math inline">\(\delta_{i}\)</span>为奇异值，则有<span class="math inline">\(Av_{i} = \sqrt{\lambda_{i}}u_{i}\)</span></p>
<p>假设矩阵<span class="math inline">\(A\)</span>的秩为<span class="math inline">\(rank(A)=r\)</span>，则<span class="math inline">\(rank（A^{T}A）=rank(AA^{T})=rank(A)=r\)</span>，则对称矩阵<span class="math inline">\(A^{T}A\)</span>有<span class="math inline">\(r\)</span>个非零的特征值，因此对于这<span class="math inline">\(r\)</span>个特征值对应的特征向量都有<span class="math inline">\(Av_{i}\ne0\)</span>,而为<span class="math inline">\(0\)</span>的特征值对应的特征向量都有<span class="math inline">\(Av_{i}=0\)</span></p>
<p>因此，由<span class="math inline">\(u_1,u_2,\cdots,u_r\)</span>组成的基是一个正交基，如果<span class="math inline">\(r&lt;m\)</span>，通过正交化将其扩展为<span class="math inline">\(R^{m}\)</span>上的正交基</p>
<center>
$AV=A(v_{1},v_{2},,v_{n})\ =(Av_{1},Av_{2},,Av_{r},0,0,,0)\ =(<em>{1}u</em>{1},<em>{2}u</em>{2},,<em>{r}u</em>{r},0,0,.0) =U\ A=UV_{T} $
</center>
<p><span class="math inline">\(v_{i}\)</span>是对称矩阵<span class="math inline">\(A^{T}A\)</span>的特征向量，称为<span class="math inline">\(A\)</span>的右奇异向量，实际上<span class="math inline">\(u_{i}\)</span>是<span class="math inline">\(AA^{T}\)</span>的特征向量，称为<span class="math inline">\(A\)</span>的左奇异向量。</p>
写成分块形式如下
<center>
$A=
<span class="math display">\[\begin{bmatrix}
v^{T}_{1} \\ 
\vdots \\ 
v^{T}_{k}\\ \hline
v^{T}_{k+1}\\
\vdots \\
v^{T}_{n}
\end{bmatrix}\]</span>
\ A=
<span class="math display">\[\begin{bmatrix}
u_{1} &amp; \cdots &amp; u_{k}  
\end{bmatrix}\begin{bmatrix}
\sigma_{1} &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \sigma_{k}  
\end{bmatrix}\begin{bmatrix}
v^{T}_{1}\\
\vdots\\
v^{T}_{k}   
\end{bmatrix}\]</span>
<ul>
<li><span class="math display">\[\begin{bmatrix}
u_{k+1} &amp; \cdots &amp; u_{m}  
\end{bmatrix}\begin{bmatrix}
&amp; &amp; \\
&amp; 0 &amp; \\
&amp; &amp; \\  
\end{bmatrix}\begin{bmatrix}
v^{T}_{k+1}\\
\vdots\\
v^{T}_{n}   
\end{bmatrix}\]</span>
\ A=
<span class="math display">\[\begin{bmatrix}
u_{1} &amp; \cdots &amp; u_{k}  
\end{bmatrix}\begin{bmatrix}
\sigma_{1} &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \sigma_{k}  
\end{bmatrix}\begin{bmatrix}
v^{T}_{1}\\
\vdots\\
v^{T}_{k}   
\end{bmatrix}\]</span>
$</li>
</ul>
</center>
<p>奇异值的意义跟特征值的意义相似，正交基<span class="math inline">\(U_{mm}\)</span>表示原空间的正交基，正交基<span class="math inline">\(V_{nn}\)</span>表示目标空间的正交基，而对角矩阵<span class="math inline">\(\Lambda\)</span>表示变换的重要性</p>
<h2 id="奇异值的应用">奇异值的应用</h2>
<h4 id="数据压缩">数据压缩</h4>
<p>从分解公式看出，如果矩阵的秩<span class="math inline">\(r\)</span>远小于<span class="math inline">\(m,n\)</span>，则矩阵可以压缩标示而且又不失真，特别的如果忽略小的奇异值，还能对数据进行压缩，比如一张图像就是一个大的二维矩阵，如果是彩色的就是三个大矩阵，比如一幅<span class="math inline">\(1000*1000\)</span>的图像<span class="math inline">\(A\)</span>，存储就需要<span class="math inline">\(1000000\)</span>个像素了，如果矩阵的秩是<span class="math inline">\(r\)</span>，则总共需要存储的数据是<span class="math inline">\(1000*r+r*r+1000+r\)</span>,如果考虑<span class="math inline">\(k\)</span>大的特征值，只需要<span class="math inline">\(1000*k+k*k+1000+k\)</span></p>
下面给出一个图像进行svd分解后选取不同的特征值进行图像还原的效果
<center>
<img src="/img/lena.jpg"> <img src="/img/6.jpg"> <img src="/img/pic.jpg"> <img src="/img/7.jpg">
</center>
<h4 id="求解pca">求解PCA</h4>
<h4 id="隐语义分析latent-semantic-analysis">隐语义分析(Latent Semantic Analysis)</h4>
在文本处理中，潜在语义分析（LSA）假设在词项和文档之间有一个潜在语义层，词汇和语义产生关联，文档也和语义产生关联。这样通过语义概念，可以将词项和文档放在一个语义空间中观察分析。比如文档分类问题，隐含的主题可以理解为文档属于什么主题的文档(体育，娱乐，科技等)，LSA使用SVD分解来求解，下面以一个例子来说明，假设有3个文档
<center>
<img src="/img/8.jpg">
</center>
查询词：gold silver truck 首先把文档分词组织成一个二维矩阵，查询词组织成一个向量，如下
<center>
<img src="/img/9.jpg">
</center>
对矩阵<span class="math inline">\(A\)</span>进行SVD分解，结果如下
<center>
<img src="/img/10.jpg">
</center>
只保留2个奇异值，则变为
<center>
<img src="/img/11.jpg">
</center>
这样可以求得三个文档在语义空间上的映射为
<center>
d1(-0.4945, 0.6492)<br>
d2(-0.6458, -0.7194)<br>
d3(-0.5817, 0.2469)
</center>
<p>将查询词映射到语义空间</p>
<center>
<img src="/img/12.jpg">
</center>
这样就可以用相似性来度量查询词跟文档的相关性了
<center>
<img src="/img/13.jpg">
</center>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/03/13/curl-linux/" rel="prev" title="Linux下curl的用法及shell处理json数据介绍">
                Linux下curl的用法及shell处理json数据介绍 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2017/04/06/matrix decomposition/"
           data-title="矩阵分解及其应用" data-url="http://yoursite.com/2017/04/06/matrix decomposition/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="jingchen" />
          <p class="site-author-name" itemprop="name">jingchen</p>
           
              <p class="site-description motion-element" itemprop="description">靖哥哥的技术博客</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#预备"><span class="nav-number">1.</span> <span class="nav-text">预备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的几何意义"><span class="nav-number">2.</span> <span class="nav-text">矩阵的几何意义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方阵的特征值及特征向量"><span class="nav-number">3.</span> <span class="nav-text">方阵的特征值及特征向量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#矩阵相似的意义"><span class="nav-number">3.0.1.</span> <span class="nav-text">矩阵相似的意义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#特征值及特征向量的意义"><span class="nav-number">3.0.2.</span> <span class="nav-text">特征值及特征向量的意义</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的奇异值分解"><span class="nav-number">4.</span> <span class="nav-text">矩阵的奇异值分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#奇异值的应用"><span class="nav-number">5.</span> <span class="nav-text">奇异值的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数据压缩"><span class="nav-number">5.0.1.</span> <span class="nav-text">数据压缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#求解pca"><span class="nav-number">5.0.2.</span> <span class="nav-text">求解PCA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#隐语义分析latent-semantic-analysis"><span class="nav-number">5.0.3.</span> <span class="nav-text">隐语义分析(Latent Semantic Analysis)</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jingchen</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"zhanliqing"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  
















  





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
